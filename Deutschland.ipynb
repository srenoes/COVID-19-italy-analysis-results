{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook contains first of all stuff to collect German Bundesland Data from differnt sources\n",
    "# And also saves it to the github (also cloned or forked versions)\n",
    "# Skript for italy I will also provide but I have to copy it out. \n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "from lmfit import Model\n",
    "\n",
    "from zipfile import  ZipFile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# load cumulative case data from wikipedia (Robert Koch based)\n",
    "# change format and correct stuff \n",
    "data_laender=pd.read_html('https://de.wikipedia.org/wiki/COVID-19-F%C3%A4lle_in_Deutschland')\n",
    "data_laender=pd.DataFrame(data_laender[3])\n",
    "data_laender=data_laender.dropna().reset_index()\n",
    "\n",
    "date0=datetime(2020,2,22)# needs to be 2 less because of freaking column indexing\n",
    "dates=[date0+timedelta(n) for n in range(len(data_laender.T))]\n",
    "\n",
    "data_laender.columns=dates\n",
    "bundeslaender=data_laender.iloc[0:16,1]\n",
    "data_laender=data_laender.iloc[0:-2,2:]\n",
    "columns=data_laender.columns\n",
    "data_laender.replace(to_replace='—',value=0.0,inplace=True)\n",
    "data_laender=pd.DataFrame(data_laender.values.astype(np.float64)/1.0)\n",
    "data_laender['Bundesland']=bundeslaender\n",
    "data_laender.set_index('Bundesland',inplace=True)\n",
    "data_laender.columns=columns\n",
    "\n",
    "#correct 1.000 = 1000.0 artefacts\n",
    "data_laender[data_laender.round()!=data_laender]=data_laender[data_laender.round()!=data_laender]*1000.0\n",
    "\n",
    "\n",
    "# This here is about data about the Bundesländer, I include only population related things\n",
    "data_laender2=pd.read_html('https://de.wikipedia.org/wiki/Land_(Deutschland)')\n",
    "data_laender2=data_laender2[0]\n",
    "#include iso3166_2 for merge with geodata\n",
    "data_laender2['iso_3166_2']='DE-'+data_laender2.iloc[:,2]\n",
    "\n",
    "data_laender2=data_laender2.set_index('Land').iloc[:-1,7:]\n",
    "\n",
    "data_laender2.iloc[:,0]=np.where(data_laender2.iloc[:,0]<100,data_laender2.iloc[:,0]*1000,data_laender2.iloc[:,0])\n",
    "data_laender2.iloc[:,1]=data_laender2.iloc[:,1]/1000.0\n",
    "data_laender2.iloc[:,2]=data_laender2.iloc[:,2]*1.0\n",
    "data_laender2.iloc[:,3]=data_laender2.iloc[:,3]*0.1\n",
    "data_laender2.drop('Sprachen',axis=1,inplace=True)\n",
    "\n",
    "#fix strange columns due to wikipedia\n",
    "data_laender2.columns=['Flaeche_km2','Einwohner_Mio','Einwohner_per_km2','Auslaender_proc','iso_3166_2']\n",
    "\n",
    "#check if all columns are float for json\n",
    "#data_laender2.info()\n",
    "\n",
    "data_laender=data_laender.join(data_laender2)\n",
    "\n",
    "# display and check all numeric is float64 (lmfit is otherwise in trouble with storing sav files == json)\n",
    "#data_laender.info()\n",
    "\n",
    "#save to the repository\n",
    "last_date=str(columns[-1].date().isoformat())\n",
    "data_laender.to_csv('./Deutschland_Bundeslander_cumdata_pandas_until_'+last_date+'.csv');\n",
    "data_laender.to_csv('./Deutschland_Bundeslander_cumdata_pandas.csv');\n",
    "\n",
    "#now get the geoinformation data needed for geopandas commented out just activate if you need\n",
    "\n",
    "# also look at https://www.naturalearthdata.com/downloads/\n",
    "# https://stackoverflow.com/questions/18885175/read-a-zipped-file-as-a-pandas-dataframe\n",
    "# https://stackoverflow.com/questions/11914472/stringio-in-python3\n",
    "#https://stackoverflow.com/questions/23419322/download-a-zip-file-and-extract-it-in-memory-using-python3\n",
    "\n",
    "\n",
    "\n",
    "#r = requests.get('https://naciscdn.org/naturalearth/10m/cultural/ne_10m_admin_1_states_provinces.zip')\n",
    "#zip_regions=ZipFile(BytesIO(r.content))\n",
    "#zip_regions.extractall('./natural_earth_admin1_large')\n",
    "\n",
    "# load map for geopandas (large or high quality needed, medium = Canada Us)\n",
    "gdf = gpd.read_file('./natural_earth_admin1_large/ne_10m_admin_1_states_provinces.shp')\n",
    "gdf.set_index(['iso_a2','name_vi'],inplace=True)\n",
    "gdf.sort_values(['iso_a2','name_vi'],inplace=True)\n",
    "gdf\n",
    "map_germany=gdf.loc[('DE',slice(None))]\n",
    "\n",
    "# now change index of data_laender to iso_3166_2 and join on map_germany\n",
    "\n",
    "map_germany.set_index('iso_3166_2',inplace=True)\n",
    "map_germany=map_germany.join(data_laender.set_index('iso_3166_2'))\n",
    "map_germany=map_germany.loc[:,'geometry':]\n",
    "\n",
    "#map_germany.info()\n",
    "\n",
    "\n",
    "#write to file. Does not work yet. I dont know why\n",
    "#map_germany.to_file('./Deutschland_Bundeslander_cumdata_geopandas_until_'+last_date+'.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# below preliminary code for optimization. Note:  Data typically is selected so that only late data is included or weighted more\n",
    "# I am not sure yet what is the appropriate way, but for example italian data looks very nice (for some) when fitted with all data,\n",
    "# but it predicts very low R0 values, were most of the people in the field get values around 2ish I would say.\n",
    "# Last 7 data selected and fitted gives for example R0=2 but confidence for beta and gamma is worse, an so are the confidence bands\n",
    "\n",
    "# This code will end up being a script to fetch data from wikipedia for cum cases and for population data\n",
    "# And I will include some script for loading map data for the use in geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from lmfit import Model\n",
    "\n",
    "\n",
    "\n",
    "# Make an objective function for optimization of italian data to SIR model\n",
    "def SIR_model_without_R(t, y,beta,gamma,N):\n",
    "    S=y[0]\n",
    "    I=y[1]\n",
    "    dSdt=-beta*I*S/N\n",
    "    dIdt=beta*I*S/N-gamma*I    \n",
    "    return [dSdt,dIdt]\n",
    "\n",
    "def fit_function(t,beta,gamma,S0,I0,N):\n",
    "    sol= solve_ivp(lambda t,y: SIR_model_without_R(t,y,beta,gamma,N), \n",
    "                   [0, max(t)],(S0,I0),teval=np.arange(0,max(t),1e-3),\n",
    "                   dense_output=True,rtol=1e-10,atol=1e-20)\n",
    "    y=sol.sol(t)\n",
    "    return np.cumsum(y[1])\n",
    "\n",
    "def model_function(t,beta,gamma,S0,I0,N):\n",
    "\n",
    "    sol= solve_ivp(lambda t,y: SIR_model_without_R(t,y,beta,gamma,N), \n",
    "                   [0, max(t)],(S0,I0),teval=np.arange(0,max(t),1e-3),\n",
    "                   dense_output=True,rtol=1e-10,atol=1e-20)\n",
    "    y=sol.sol(t)\n",
    "    return y\n",
    "\n",
    "\n",
    "fit_Data=data_laender.copy()\n",
    "\n",
    "cum_model = Model(fit_function)\n",
    "cum_model.set_param_hint('beta',value=6,min=0,vary=True)\n",
    "cum_model.set_param_hint('gamma',value=6,min=0,vary=True)\n",
    "cum_model.set_param_hint('S0',min=0,vary=False)\n",
    "cum_model.set_param_hint('I0',min=0,vary=False)\n",
    "cum_model.set_param_hint('N',min=0,vary=False)\n",
    "params1 = cum_model.make_params()\n",
    "\n",
    "complete_model = Model(model_function)\n",
    "complete_model.set_param_hint('beta',value=6,min=0,vary=True)\n",
    "complete_model.set_param_hint('gamma',value=5.8,min=0,vary=True)\n",
    "complete_model.set_param_hint('S0',min=0,vary=False)\n",
    "complete_model.set_param_hint('I0',min=0,vary=False)\n",
    "complete_model.set_param_hint('N',min=0,vary=False)\n",
    "params2 = complete_model.make_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0xx 1xx 2xx 3xx 4xy 5xy 6xy 7xy 8xy 9xy 10xy 11xy 12xy 13xy 14xy 15xy "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lmfit.model import save_modelresult\n",
    "from lmfit.model import load_modelresult\n",
    "from pathlib import Path\n",
    "    \n",
    "\n",
    "def fit_model(gmodel,gmodel_2,Data,t,S0,I0,N,title1,title2,ax):\n",
    "    #print(t,Data,N,Data[0])\n",
    "    result=gmodel.fit(Data,t=t,S0=N,I0=Data[0],N=N)\n",
    "    #print(result.fit_report())\n",
    "    tnew=np.arange(len(Data)*3)\n",
    "    best_fit=gmodel.eval(t=tnew,beta=result.values['beta'],gamma=result.values['gamma'],S0=N,I0=Data[0],N=N)\n",
    "    \n",
    "    \n",
    "    del_fit = result.eval_uncertainty(t=tnew)\n",
    "    upper_band=best_fit+del_fit\n",
    "    lower_band=best_fit-del_fit\n",
    "    ax[0].plot(t, Data, 'bo',label='Data')\n",
    "    ax[0].plot(tnew, best_fit, 'r-', label='best fit SIR model')\n",
    "    ax[0].plot(tnew,upper_band, 'k-', label='conf bands')\n",
    "    ax[0].plot(tnew,lower_band,'k-')\n",
    "    ax[0].legend(loc='best',fontsize=18)\n",
    "    ax[0].set_title(title1,fontsize=20)\n",
    "    ax[0].set_xlabel('time/days',fontsize=18)\n",
    "    ax[0].set_ylabel('Total infected persons',fontsize=18)\n",
    "    plt.setp(ax[0].get_yticklabels(),fontsize=16)\n",
    "    plt.setp(ax[0].get_xticklabels(),fontsize=16)\n",
    "        \n",
    "    tnew2=np.arange(0,len(Data)*3,0.01)    \n",
    "    best_SI=gmodel_2.eval(t=tnew2,beta=result.values['beta'],gamma=result.values['gamma'],S0=N,I0=Data[0],N=N)\n",
    "    ax[1].plot(tnew2,best_SI[1].T/N*100,'k-')\n",
    "    ax[2].plot(tnew2,best_SI[0].T/N*100)\n",
    "    ax[1].set_xlabel('time/days',fontsize=18)\n",
    "    ax[1].set_ylabel('I (infected persons) / %',fontsize=18)\n",
    "    ax[1].set_title(title2,fontsize=20)    \n",
    "    ax[2].set_ylabel('S (Not infected persons) / %',fontsize=18)\n",
    "    plt.setp(ax[1].get_yticklabels(),fontsize=16)\n",
    "    plt.setp(ax[1].get_xticklabels(),fontsize=16)\n",
    "    plt.setp(ax[2].get_yticklabels(),fontsize=16)\n",
    "    \n",
    "    Data_plot=pd.DataFrame({'t':t,'Data':Data})\n",
    "    best_fit=pd.DataFrame({'t':tnew,'best_fit':best_fit})\n",
    "    upper=pd.DataFrame({'t':tnew,'upper_band':upper_band})\n",
    "    lower=pd.DataFrame({'t':tnew,'lower_band':lower_band})\n",
    "    best_fit_S=pd.DataFrame({'t':tnew2,'best_fit_S':best_SI[0].T})\n",
    "    best_fit_I=pd.DataFrame({'t':tnew2,'best_fit_I':best_SI[1].T})\n",
    "    \n",
    "    return result,Data_plot,best_fit,upper,lower,best_fit_S,best_fit_I\n",
    "\n",
    "\n",
    "\n",
    "fit_Data=data_laender.copy()\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=[20,10])    \n",
    "ax2=ax[1].twinx()\n",
    "ax=[ax[0],ax[1],ax2]\n",
    "print(len(fit_Data),end=' ')\n",
    "\n",
    "fit_result_Data=pd.DataFrame({'lmfit_result_files':[],'Data_plots':[],'best_fits':[],\n",
    "                       'upper':[],'lower':[],'best_fit_S':[],'best_fit_I':[]})\n",
    "try:\n",
    "    fit_result_Data=pd.read_json('Germany_SIR_fit.json')\n",
    "except:\n",
    "    pass\n",
    "for n in range(len(fit_Data)):\n",
    "    print(n,end='')\n",
    "    if (n<len(fit_result_Data)):\n",
    "        if fit_result_Data.loc[n][0]!=None:\n",
    "            print('s',end=' ')\n",
    "            continue\n",
    "    Data=fit_Data.iloc[n,:-3].values\n",
    "    N=fit_Data.iloc[n,-2]\n",
    "    if max(Data)>0:\n",
    "        while Data[0]==0:\n",
    "            Data=Data[1:]\n",
    "    else:\n",
    "        fit_result_Data.loc[n]=[None,None,None,None,None,None,None]\n",
    "        continue\n",
    "    t=np.arange(len(Data))\n",
    "    S0=N\n",
    "    I0=Data[0]\n",
    "    try:\n",
    "        result,Data_plot,best_fit,upper,lower,best_fit_S,best_fit_I=fit_model(cum_model,complete_model,Data,t,S0,I0,N,f'Cumulative infections in {bundeslaender[n]}',f'S and I {bundeslaender[n]}',ax);\n",
    "        print('x',end='')\n",
    "        #save result to separate file\n",
    "        result_file=f'Deutschland_SIR_fitresult_{n:003}_{bundeslaender[n]}.sav'\n",
    "        save_modelresult(result,result_file)\n",
    "\n",
    "        #save figure to png\n",
    "    \n",
    "        if Path(f'Deutschland_SIR_fitresult_{n:003}_{bundeslaender[n]}.png').is_file():\n",
    "            print ('x',end=' ')\n",
    "        else:\n",
    "            fig.savefig(f'Deutschland_SIR_fitresult_{n:003}_{bundeslaender[n]}.png', bbox_inches='tight', dpi=400);\n",
    "            print ('y',end=' ')\n",
    "        fit_result_Data.loc[n]=[result_file,Data_plot,best_fit,upper,lower,best_fit_S,best_fit_I]\n",
    "        \n",
    "    except:\n",
    "        fit_result_Data.loc[n]=[None,None,None,None,None,None,None]\n",
    "    ax[0].clear();\n",
    "    ax[1].clear();\n",
    "    ax[2].clear(); \n",
    "\n",
    "fig.clf()\n",
    "fit_result_Data.to_json('Germany_SIR_fit.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
